{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2024-05-03 21:57:19 mixins:170] Tokenizer SentencePieceTokenizer initialized with 128 tokens\n",
      "[NeMo I 2024-05-03 21:57:19 ctc_bpe_models_AddLayer:63] \n",
      "    Replacing placeholder number of classes (-1) with actual number of classes - 128\n",
      "[NeMo I 2024-05-03 21:57:39 collections:196] Dataset loaded with 278627 files totalling 948.67 hours\n",
      "[NeMo I 2024-05-03 21:57:39 collections:197] 2614 files were filtered totalling 12.38 hours\n",
      "[NeMo I 2024-05-03 21:57:40 collections:196] Dataset loaded with 2703 files totalling 5.39 hours\n",
      "[NeMo I 2024-05-03 21:57:40 collections:197] 0 files were filtered totalling 0.00 hours\n",
      "[NeMo I 2024-05-03 21:57:40 collections:196] Dataset loaded with 2620 files totalling 5.40 hours\n",
      "[NeMo I 2024-05-03 21:57:40 collections:197] 0 files were filtered totalling 0.00 hours\n",
      "[NeMo I 2024-05-03 21:57:40 features:289] PADDING: 0\n",
      "torch.Size([129]) tensor([-0.0063, -0.0259,  0.0100,  0.0430,  0.0389,  0.0362,  0.0263, -0.0033,\n",
      "         0.0153, -0.0043, -0.0227,  0.0037,  0.0334,  0.0083, -0.0391, -0.0242,\n",
      "         0.0132,  0.0360, -0.0074,  0.0431, -0.0284,  0.0335,  0.0065,  0.0013,\n",
      "        -0.0435, -0.0369, -0.0422,  0.0393, -0.0158, -0.0361,  0.0052,  0.0289,\n",
      "        -0.0436,  0.0285, -0.0215, -0.0381, -0.0428, -0.0412, -0.0350, -0.0317,\n",
      "        -0.0074,  0.0340,  0.0346,  0.0261, -0.0015, -0.0068, -0.0043,  0.0139,\n",
      "         0.0287, -0.0240,  0.0134,  0.0141, -0.0421, -0.0412, -0.0431,  0.0072,\n",
      "        -0.0388,  0.0391, -0.0002, -0.0330,  0.0351, -0.0255,  0.0038,  0.0005,\n",
      "         0.0267,  0.0430, -0.0214, -0.0100,  0.0031,  0.0374, -0.0298, -0.0440,\n",
      "        -0.0047, -0.0275, -0.0273, -0.0157, -0.0276,  0.0044,  0.0184,  0.0112,\n",
      "         0.0111, -0.0101,  0.0363,  0.0360,  0.0272,  0.0159,  0.0321, -0.0057,\n",
      "         0.0236,  0.0020,  0.0270,  0.0011,  0.0164, -0.0300, -0.0312,  0.0367,\n",
      "        -0.0363,  0.0018,  0.0344,  0.0385,  0.0045, -0.0402,  0.0081,  0.0281,\n",
      "         0.0223,  0.0162, -0.0064, -0.0200,  0.0284, -0.0317, -0.0378,  0.0051,\n",
      "         0.0286, -0.0120, -0.0316,  0.0387, -0.0177,  0.0167,  0.0325, -0.0227,\n",
      "        -0.0426, -0.0008, -0.0310, -0.0332, -0.0181,  0.0148,  0.0424, -0.0173,\n",
      "        -0.0340])\n",
      "torch.Size([129]) tensor([-0.0063, -0.0259,  0.0100,  0.0430,  0.0389,  0.0362,  0.0263, -0.0033,\n",
      "         0.0153, -0.0043, -0.0227,  0.0037,  0.0334,  0.0083, -0.0391, -0.0242,\n",
      "         0.0132,  0.0360, -0.0074,  0.0431, -0.0284,  0.0335,  0.0065,  0.0013,\n",
      "        -0.0435, -0.0369, -0.0422,  0.0393, -0.0158, -0.0361,  0.0052,  0.0289,\n",
      "        -0.0436,  0.0285, -0.0215, -0.0381, -0.0428, -0.0412, -0.0350, -0.0317,\n",
      "        -0.0074,  0.0340,  0.0346,  0.0261, -0.0015, -0.0068, -0.0043,  0.0139,\n",
      "         0.0287, -0.0240,  0.0134,  0.0141, -0.0421, -0.0412, -0.0431,  0.0072,\n",
      "        -0.0388,  0.0391, -0.0002, -0.0330,  0.0351, -0.0255,  0.0038,  0.0005,\n",
      "         0.0267,  0.0430, -0.0214, -0.0100,  0.0031,  0.0374, -0.0298, -0.0440,\n",
      "        -0.0047, -0.0275, -0.0273, -0.0157, -0.0276,  0.0044,  0.0184,  0.0112,\n",
      "         0.0111, -0.0101,  0.0363,  0.0360,  0.0272,  0.0159,  0.0321, -0.0057,\n",
      "         0.0236,  0.0020,  0.0270,  0.0011,  0.0164, -0.0300, -0.0312,  0.0367,\n",
      "        -0.0363,  0.0018,  0.0344,  0.0385,  0.0045, -0.0402,  0.0081,  0.0281,\n",
      "         0.0223,  0.0162, -0.0064, -0.0200,  0.0284, -0.0317, -0.0378,  0.0051,\n",
      "         0.0286, -0.0120, -0.0316,  0.0387, -0.0177,  0.0167,  0.0325, -0.0227,\n",
      "        -0.0426, -0.0008, -0.0310, -0.0332, -0.0181,  0.0148,  0.0424, -0.0173,\n",
      "        -0.0340])\n",
      "[NeMo I 2024-05-03 21:57:40 mixins:170] Tokenizer SentencePieceTokenizer initialized with 128 tokens\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2024-05-03 21:57:40 modelPT:161] If you intend to do training or fine-tuning, please call the ModelPT.setup_training_data() method and provide a valid configuration file to setup the train data loader.\n",
      "    Train config : \n",
      "    manifest_filepath: /home/jykang/database/train_clean_100.json,/home/jykang/database/train_clean_360.json,/home/jykang/database/train_other_500.json\n",
      "    sample_rate: 16000\n",
      "    batch_size: 24\n",
      "    shuffle: false\n",
      "    num_workers: 8\n",
      "    pin_memory: true\n",
      "    max_duration: 16.7\n",
      "    min_duration: 0.1\n",
      "    is_tarred: false\n",
      "    tarred_audio_filepaths: null\n",
      "    shuffle_n: 2048\n",
      "    bucketing_strategy: synced_randomized\n",
      "    bucketing_batch_size: null\n",
      "    \n",
      "[NeMo W 2024-05-03 21:57:40 modelPT:168] If you intend to do validation, please call the ModelPT.setup_validation_data() or ModelPT.setup_multiple_validation_data() method and provide a valid configuration file to setup the validation data loader(s). \n",
      "    Validation config : \n",
      "    manifest_filepath: /home/jykang/database/dev_clean.json\n",
      "    sample_rate: 16000\n",
      "    batch_size: 24\n",
      "    shuffle: false\n",
      "    use_start_end_token: false\n",
      "    num_workers: 8\n",
      "    pin_memory: true\n",
      "    \n",
      "[NeMo W 2024-05-03 21:57:40 modelPT:174] Please call the ModelPT.setup_test_data() or ModelPT.setup_multiple_test_data() method and provide a valid configuration file to setup the test data loader(s).\n",
      "    Test config : \n",
      "    manifest_filepath: /home/jykang/database/test_clean.json\n",
      "    sample_rate: 16000\n",
      "    batch_size: 24\n",
      "    shuffle: false\n",
      "    use_start_end_token: false\n",
      "    num_workers: 8\n",
      "    pin_memory: true\n",
      "    \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2024-05-03 21:57:40 features:289] PADDING: 0\n",
      "[NeMo I 2024-05-03 21:57:41 save_restore_connector:250] Model EncDecCTCModelBPE was successfully restored from /data/jykang/NeMo/nemo_experiments/CTC_Teacher_Decoder_Reusing/Conformer-CTC-BPE-Fitnet-AddLayer/2024-04-04_23-44-32/checkpoints/Conformer-CTC-BPE-Fitnet-AddLayer.nemo.\n",
      "[NeMo I 2024-05-03 21:57:41 modelPT:1220] Model checkpoint restored from nemo file with path : `/data/jykang/NeMo/nemo_experiments/CTC_Teacher_Decoder_Reusing/Conformer-CTC-BPE-Fitnet-AddLayer/2024-04-04_23-44-32/checkpoints/Conformer-CTC-BPE-Fitnet-AddLayer.nemo`\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append(r'/data/jykang/NeMo')\n",
    "\n",
    "import pytorch_lightning as pl\n",
    "from omegaconf import OmegaConf\n",
    "\n",
    "from nemo.collections.asr.models.ctc_bpe_models_AddLayer import EncDecCTCModelBPE\n",
    "from nemo.core.config import hydra_runner\n",
    "from nemo.utils import logging\n",
    "from nemo.utils.exp_manager import exp_manager\n",
    "\n",
    "import torch\n",
    "\n",
    "import yaml\n",
    "config_path = '/data/jykang/NeMo/examples/asr/asr_ctc/asr_ctc_distil/conf/conformer_ctc_bpe_Fitnet_AddLayer.yaml'\n",
    "with open (config_path, 'r') as f:\n",
    "    config = OmegaConf.load(f)\n",
    "    \n",
    "def train(cfg):\n",
    "   \n",
    "    asr_model = EncDecCTCModelBPE(cfg = cfg['model'], trainer =None)\n",
    "    \n",
    "    te_tmp_bias = asr_model.state_dict()['decoder.decoder_layers.0.bias']\n",
    "    te_tmp_weight = asr_model.state_dict()['decoder.decoder_layers.0.weight']\n",
    "    a = torch.rand(129)\n",
    "    a = te_tmp_bias.clone()\n",
    "    print(a.shape, a)\n",
    "    print(te_tmp_bias.shape, te_tmp_bias)\n",
    "    # Initialize the weights of the model from another model, if provided via config\n",
    "    asr_model.maybe_init_from_pretrained_checkpoint(cfg)\n",
    "    \n",
    "    # # teacher decoder load\n",
    "    # te_dec_bias = torch.load('/data/jykang/NeMo/data/decoder/te_dec_bias.pt')\n",
    "    # te_dec_weight = torch.load('/data/jykang/NeMo/data/decoder/te_dec_weight.pt')\n",
    "    # with torch.no_grad():\n",
    "    #     asr_model.state_dict()['decoder.decoder_layers.0.bias'].copy_(te_dec_bias)\n",
    "    #     asr_model.state_dict()['decoder.decoder_layers.0.weight'].copy_(te_dec_weight)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        asr_model.state_dict()['decoder.decoder_layers.0.bias'].copy_(a)\n",
    "        asr_model.state_dict()['decoder.decoder_layers.0.weight'].copy_(te_tmp_weight)\n",
    "    return a, asr_model.state_dict()['decoder.decoder_layers.0.bias'], te_tmp_bias\n",
    "    \n",
    "\n",
    "a, b, c = train(config)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([129])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([129])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([129])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nemo_rnnt",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
